{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b122880-d1f0-4252-90fa-52c6d8613ea4",
   "metadata": {},
   "source": [
    "# Chapter-7 Deploying ONNX Models on Edge Devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf6f5d-a611-402c-a39c-34601be3061c",
   "metadata": {},
   "source": [
    "#### In this notebook, we will learn about ONNX Runtime C++ APIs and see how ONNX Runtime can be used to deploy the models on the edge devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aecbada-3582-43f2-9d31-313ad87e557f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-04-03 21:49:12--  https://github.com/microsoft/onnxruntime/releases/download/v1.21.0/onnxruntime-linux-x64-1.21.0.tgz\n",
      "Resolving github.com (github.com)... 20.207.73.82\n",
      "Connecting to github.com (github.com)|20.207.73.82|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/156939672/d9f524e2-f059-49ca-a237-afa886d0f73e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250403%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250403T161810Z&X-Amz-Expires=300&X-Amz-Signature=7698ae6a2e028603cf97411d3373a98c34dfea39b914605a9022c51afee6a731&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Donnxruntime-linux-x64-1.21.0.tgz&response-content-type=application%2Foctet-stream [following]\n",
      "--2025-04-03 21:49:12--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/156939672/d9f524e2-f059-49ca-a237-afa886d0f73e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250403%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250403T161810Z&X-Amz-Expires=300&X-Amz-Signature=7698ae6a2e028603cf97411d3373a98c34dfea39b914605a9022c51afee6a731&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Donnxruntime-linux-x64-1.21.0.tgz&response-content-type=application%2Foctet-stream\n",
      "185.199.108.133, 185.199.109.133, 185.199.110.133, ...busercontent.com)... \n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 7585530 (7.2M) [application/octet-stream]\n",
      "Saving to: ‘onnxruntime-linux-x64-1.21.0.tgz’\n",
      "\n",
      "onnxruntime-linux-x 100%[===================>]   7.23M  8.55MB/s    in 0.8s    \n",
      "\n",
      "2025-04-03 21:49:15 (8.55 MB/s) - ‘onnxruntime-linux-x64-1.21.0.tgz’ saved [7585530/7585530]\n",
      "\n",
      "onnxruntime-linux-x64-1.21.0/\n",
      "onnxruntime-linux-x64-1.21.0/include/\n",
      "onnxruntime-linux-x64-1.21.0/include/core/\n",
      "onnxruntime-linux-x64-1.21.0/include/core/providers/\n",
      "onnxruntime-linux-x64-1.21.0/include/core/providers/resource.h\n",
      "onnxruntime-linux-x64-1.21.0/include/core/providers/custom_op_context.h\n",
      "onnxruntime-linux-x64-1.21.0/include/onnxruntime_run_options_config_keys.h\n",
      "onnxruntime-linux-x64-1.21.0/include/cpu_provider_factory.h\n",
      "onnxruntime-linux-x64-1.21.0/include/onnxruntime_lite_custom_op.h\n",
      "onnxruntime-linux-x64-1.21.0/include/onnxruntime_cxx_api.h\n",
      "onnxruntime-linux-x64-1.21.0/include/onnxruntime_cxx_inline.h\n",
      "onnxruntime-linux-x64-1.21.0/include/onnxruntime_float16.h\n",
      "onnxruntime-linux-x64-1.21.0/include/onnxruntime_c_api.h\n",
      "onnxruntime-linux-x64-1.21.0/include/onnxruntime_session_options_config_keys.h\n",
      "onnxruntime-linux-x64-1.21.0/include/provider_options.h\n",
      "onnxruntime-linux-x64-1.21.0/LICENSE\n",
      "onnxruntime-linux-x64-1.21.0/ThirdPartyNotices.txt\n",
      "onnxruntime-linux-x64-1.21.0/lib/\n",
      "onnxruntime-linux-x64-1.21.0/lib/cmake/\n",
      "onnxruntime-linux-x64-1.21.0/lib/cmake/onnxruntime/\n",
      "onnxruntime-linux-x64-1.21.0/lib/cmake/onnxruntime/onnxruntimeTargets-release.cmake\n",
      "onnxruntime-linux-x64-1.21.0/lib/cmake/onnxruntime/onnxruntimeConfigVersion.cmake\n",
      "onnxruntime-linux-x64-1.21.0/lib/cmake/onnxruntime/onnxruntimeTargets.cmake\n",
      "onnxruntime-linux-x64-1.21.0/lib/cmake/onnxruntime/onnxruntimeConfig.cmake\n",
      "onnxruntime-linux-x64-1.21.0/lib/libonnxruntime.so.1\n",
      "onnxruntime-linux-x64-1.21.0/lib/libonnxruntime.so\n",
      "onnxruntime-linux-x64-1.21.0/lib/pkgconfig/\n",
      "onnxruntime-linux-x64-1.21.0/lib/pkgconfig/libonnxruntime.pc\n",
      "onnxruntime-linux-x64-1.21.0/lib/libonnxruntime_providers_shared.so\n",
      "onnxruntime-linux-x64-1.21.0/lib/libonnxruntime.so.1.21.0\n",
      "onnxruntime-linux-x64-1.21.0/VERSION_NUMBER\n",
      "onnxruntime-linux-x64-1.21.0/Privacy.md\n",
      "onnxruntime-linux-x64-1.21.0/GIT_COMMIT_ID\n",
      "onnxruntime-linux-x64-1.21.0/README.md\n",
      "/mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/Ultimate-ONNX-for-Optimizing-Deep-Learning-Models/Chapter-7/deps\n",
      "--2025-04-03 21:49:16--  https://raw.githubusercontent.com/nothings/stb/master/stb_image.h\n",
      "185.199.111.133, 185.199.109.133, 185.199.110.133, ...tent.com)... \n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 283010 (276K) [text/plain]\n",
      "Saving to: ‘stb_image.h’\n",
      "\n",
      "stb_image.h           0%[                    ]       0  --.-KB/s               "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stb_image.h         100%[===================>] 276.38K  --.-KB/s    in 0.05s   \n",
      "\n",
      "2025-04-03 21:49:17 (5.04 MB/s) - ‘stb_image.h’ saved [283010/283010]\n",
      "\n",
      "--2025-04-03 21:49:17--  https://raw.githubusercontent.com/nothings/stb/master/stb_image_resize2.h\n",
      "185.199.110.133, 185.199.109.133, 185.199.111.133, ...tent.com)... \n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 452529 (442K) [text/plain]\n",
      "Saving to: ‘stb_image_resize2.h’\n",
      "\n",
      "stb_image_resize2.h 100%[===================>] 441.92K  --.-KB/s    in 0.08s   \n",
      "\n",
      "2025-04-03 21:49:17 (5.65 MB/s) - ‘stb_image_resize2.h’ saved [452529/452529]\n",
      "\n",
      "/mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/Ultimate-ONNX-for-Optimizing-Deep-Learning-Models/Chapter-7/data\n",
      "--2025-04-03 21:49:17--  https://github.com/onnx/models/raw/refs/heads/main/validated/vision/classification/resnet/model/resnet50-v2-7.onnx\n",
      "20.207.73.82thub.com (github.com)... \n",
      "connected. to github.com (github.com)|20.207.73.82|:443... \n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://media.githubusercontent.com/media/onnx/models/refs/heads/main/validated/vision/classification/resnet/model/resnet50-v2-7.onnx [following]\n",
      "--2025-04-03 21:49:17--  https://media.githubusercontent.com/media/onnx/models/refs/heads/main/validated/vision/classification/resnet/model/resnet50-v2-7.onnx\n",
      "185.199.109.133, 185.199.108.133, 185.199.111.133, ...rcontent.com)... \n",
      "connected. to media.githubusercontent.com (media.githubusercontent.com)|185.199.109.133|:443... \n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 102442452 (98M) [application/octet-stream]\n",
      "Saving to: ‘resnet50-v2-7.onnx’\n",
      "\n",
      "resnet50-v2-7.onnx  100%[===================>]  97.70M  8.05MB/s    in 12s     \n",
      "\n",
      "2025-04-03 21:49:29 (8.43 MB/s) - ‘resnet50-v2-7.onnx’ saved [102442452/102442452]\n",
      "\n",
      "--2025-04-03 21:49:29--  https://huggingface.co/spaces/ClassCat/ViT-ImageNet-Classification/resolve/main/samples/cat.jpg\n",
      "99.86.182.72, 99.86.182.94, 99.86.182.39, ...\n",
      "Connecting to huggingface.co (huggingface.co)|99.86.182.72|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 5792 (5.7K) [image/jpeg]\n",
      "Saving to: ‘cat.jpg’\n",
      "\n",
      "cat.jpg             100%[===================>]   5.66K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-04-03 21:49:30 (698 MB/s) - ‘cat.jpg’ saved [5792/5792]\n",
      "\n",
      "/mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/Ultimate-ONNX-for-Optimizing-Deep-Learning-Models/Chapter-7\n"
     ]
    }
   ],
   "source": [
    "# Download ONNX Runtime Prebuilt binaries\n",
    "!wget https://github.com/microsoft/onnxruntime/releases/download/v1.21.0/onnxruntime-linux-x64-1.21.0.tgz\n",
    "!tar -xzvf onnxruntime-linux-x64-1.21.0.tgz\n",
    "\n",
    "!mkdir deps/\n",
    "!mkdir data/\n",
    "\n",
    "%cd deps\n",
    "# Download image processing helper libraries\n",
    "!wget https://raw.githubusercontent.com/nothings/stb/master/stb_image.h -O stb_image.h\n",
    "!wget https://raw.githubusercontent.com/nothings/stb/master/stb_image_resize2.h -O stb_image_resize2.h\n",
    "\n",
    "%cd ../data\n",
    "# Download ResNet50 model from Onnx model zoo\n",
    "!wget https://github.com/onnx/models/raw/refs/heads/main/validated/vision/classification/resnet/model/resnet50-v2-7.onnx\n",
    "\n",
    "# Download a sample image of cat\n",
    "!wget https://huggingface.co/spaces/ClassCat/ViT-ImageNet-Classification/resolve/main/samples/cat.jpg\n",
    "\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19639e06-5b97-4cad-b101-aa305e371688",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpp_content = \"\"\"\n",
    "#include <iostream>\n",
    "#include <vector>\n",
    "#include <onnxruntime_cxx_api.h>\n",
    "\n",
    "#define STB_IMAGE_IMPLEMENTATION\n",
    "#define STB_IMAGE_RESIZE2_IMPLEMENTATION\n",
    "#include <stb_image.h>\n",
    "#include <stb_image_resize2.h>\n",
    "\n",
    "// ImageNet mean and std values\n",
    "const float mean[] = {0.485f, 0.456f, 0.406f};\n",
    "const float std_dev[] = {0.229f, 0.224f, 0.225f};\n",
    "\n",
    "void preprocessImage(const std::string& imagePath, std::vector<float>& inputTensorValues) {\n",
    "    int width, height, channels;\n",
    "    unsigned char* img = stbi_load(imagePath.c_str(), &width, &height, &channels, 3); // Load as RGB\n",
    "\n",
    "    if (!img) {\n",
    "        throw std::runtime_error(\"Failed to load image: \" + imagePath);\n",
    "    }\n",
    "\n",
    "    int target_width = 224, target_height = 224;\n",
    "    std::vector<unsigned char> resized_img(target_width * target_height * 3);\n",
    "\n",
    "    // Resize image to 224x224\n",
    "    stbir_resize_uint8_linear(img, width, height, 0,\n",
    "                       resized_img.data(), target_width, target_height, 0, STBIR_RGB);\n",
    "\n",
    "    // Convert to normalized float format (CHW layout)\n",
    "    for (int c = 0; c < 3; c++) {  // Loop over channels\n",
    "        for (int h = 0; h < target_height; h++) {\n",
    "            for (int w = 0; w < target_width; w++) {\n",
    "                int idx = (h * target_width + w) * 3 + c;  // HWC index\n",
    "                inputTensorValues[c * target_width * target_height + h * target_width + w] =\n",
    "                    ((float)resized_img[idx] / 255.0f - mean[c]) / std_dev[c];  // Normalize & Standardize\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    stbi_image_free(img);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int model_height = 224;\n",
    "    int model_width = 224;\n",
    "    int num_channels = 3;\n",
    "    std::string model_path = \"./data/resnet50-v2-7.onnx\";\n",
    "    std::string img_path = \"./data/cat.jpg\";\n",
    "\n",
    "    try {\n",
    "        Ort::Env env(ORT_LOGGING_LEVEL_WARNING, \"ONNXRuntimeTest\");\n",
    "        Ort::SessionOptions session_options;\n",
    "\n",
    "        // Load ResNet50 model\n",
    "        Ort::Session session(env, model_path.c_str(), session_options);\n",
    "        Ort::AllocatorWithDefaultOptions allocator;\n",
    "\n",
    "        // Get input details\n",
    "        auto input_name = session.GetInputNameAllocated(0, allocator);\n",
    "        std::vector<int64_t> input_shape = {1, num_channels, model_height, model_width}; // Batch size 1\n",
    "        \n",
    "        // Preprocess image\n",
    "        std::vector<float> input_tensor_values(num_channels * model_height * model_width, 0.0f);\n",
    "        preprocessImage(img_path, input_tensor_values);\n",
    "        \n",
    "        // Create input tensor\n",
    "        Ort::MemoryInfo memory_info = Ort::MemoryInfo::CreateCpu(OrtArenaAllocator, OrtMemTypeDefault);\n",
    "        Ort::Value input_tensor = Ort::Value::CreateTensor<float>(memory_info, input_tensor_values.data(),\n",
    "                            input_tensor_values.size(), input_shape.data(), input_shape.size());\n",
    "        \n",
    "        // Run inference\n",
    "        std::vector<const char*> input_names = {input_name.get()};\n",
    "        auto output_name = session.GetOutputNameAllocated(0, allocator);\n",
    "        std::vector<const char*> output_names = {output_name.get()};\n",
    "        std::vector<Ort::Value> output_tensors = session.Run(Ort::RunOptions{nullptr}, input_names.data(),\n",
    "                                                             &input_tensor, 1, output_names.data(), 1);\n",
    "\n",
    "        // Print top-1 predicted class index\n",
    "        float* output_data = output_tensors[0].GetTensorMutableData<float>();\n",
    "\n",
    "        int predicted_class = std::max_element(output_data, output_data + 1000) - output_data;\n",
    "        std::cout << \"Predicted Class: \" << predicted_class << std::endl;\n",
    "\n",
    "    } catch (const Ort::Exception& e) {\n",
    "        std::cerr << \"Error: \" << e.what() << std::endl;\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"resnet_inference.cpp\", \"w\") as f:\n",
    "    f.writelines(cpp_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e1296c-1d9a-4791-bc5a-3276ec5d8b1d",
   "metadata": {},
   "source": [
    "The above C++ code will load image of cat as shown below. \n",
    "\n",
    "![Image of Cat](https://huggingface.co/spaces/ClassCat/ViT-ImageNet-Classification/resolve/main/samples/cat.jpg)\n",
    "\n",
    "After loading the image, it will be resized to 224x224 pixels and standardized according to ImageNet norms. Once the image is preprocessed, it will be passed to the ONNX Runtime session for prediction. The model is expected to classify it as class 282, which corresponds to \"tiger cat,\" the closest match to a cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a6cd7b5-0abc-49e6-84ed-f63a02984faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the cpp file\n",
    "!g++ -std=c++17 -I./onnxruntime-linux-x64-1.21.0/include -I./deps/ -L./onnxruntime-linux-x64-1.21.0/lib -o resnet_inference resnet_inference.cpp -lonnxruntime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f3cfee-bf6b-4ef3-8c88-ae3a1bab4a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 282\n"
     ]
    }
   ],
   "source": [
    "# Add ONNX Runtime library path in LD_LIBRARY_PATH as we have dynamically linked this library during compilation and Run the inference\n",
    "!LD_LIBRARY_PATH=./onnxruntime-linux-x64-1.21.0/lib:$LD_LIBRARY_PATH ./resnet_inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
