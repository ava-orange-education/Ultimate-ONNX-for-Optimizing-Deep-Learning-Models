{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2bfe63b-1c70-4e3e-b6c8-c9e0740befc2",
   "metadata": {},
   "source": [
    "# Chapter-12 ONNX model from scratch and Custom Operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a496e34-d789-4cfe-9ab3-6db7cffea62a",
   "metadata": {},
   "source": [
    "#### In this notebook, we will try to develop ONNX model from scratch using building blocks provided by ONNX. Then we will also learn how to add custom operators in ONNX."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c110d840-669c-4848-b276-06f389421552",
   "metadata": {},
   "source": [
    "### Step-1 Developing ONNX model from scratch using ONNX's building blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ac192b-7c1d-4a1c-9238-b091294aa17c",
   "metadata": {},
   "source": [
    "##### For this example we will develop a simple 3 layer MLP model with relu activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e36ca4b5-38aa-4025-a65a-119d57715fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: onnx==1.18.0 in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (1.18.0)\n",
      "Requirement already satisfied: onnxruntime==1.22.0 in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (1.22.0)\n",
      "Collecting onnxscript==0.2.4\n",
      "  Downloading onnxscript-0.2.4-py3-none-any.whl (705 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.4/705.4 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: netron==8.4.3 in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (8.4.3)\n",
      "Requirement already satisfied: typing_extensions>=4.7.1 in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (from onnx==1.18.0) (4.14.1)\n",
      "Requirement already satisfied: numpy>=1.22 in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (from onnx==1.18.0) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=4.25.1 in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (from onnx==1.18.0) (6.31.1)\n",
      "Requirement already satisfied: packaging in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (from onnxruntime==1.22.0) (25.0)\n",
      "Requirement already satisfied: coloredlogs in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (from onnxruntime==1.22.0) (15.0.1)\n",
      "Requirement already satisfied: sympy in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (from onnxruntime==1.22.0) (1.13.1)\n",
      "Requirement already satisfied: flatbuffers in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (from onnxruntime==1.22.0) (25.2.10)\n",
      "Requirement already satisfied: ml_dtypes in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (from onnxscript==0.2.4) (0.5.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (from coloredlogs->onnxruntime==1.22.0) (10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (from sympy->onnxruntime==1.22.0) (1.3.0)\n",
      "Installing collected packages: onnxscript\n",
      "Successfully installed onnxscript-0.2.4\n",
      "Looking in indexes: https://download.pytorch.org/whl/cpu\n",
      "Requirement already satisfied: torch==2.6.0 in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (2.6.0+cpu)\n",
      "Requirement already satisfied: torchvision==0.21.0 in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (0.21.0+cpu)\n",
      "Requirement already satisfied: torchaudio==2.6.0 in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (2.6.0+cpu)\n",
      "Requirement already satisfied: filelock in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (from torch==2.6.0) (3.13.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (from torch==2.6.0) (1.13.1)\n",
      "Requirement already satisfied: fsspec in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (from torch==2.6.0) (2024.6.1)\n",
      "Requirement already satisfied: jinja2 in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (from torch==2.6.0) (3.1.6)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (from torch==2.6.0) (4.14.1)\n",
      "Requirement already satisfied: networkx in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (from torch==2.6.0) (3.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (from torchvision==0.21.0) (11.0.0)\n",
      "Requirement already satisfied: numpy in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (from torchvision==0.21.0) (1.26.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (from sympy==1.13.1->torch==2.6.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages (from jinja2->torch==2.6.0) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "# Install prerequisites\n",
    "!pip install onnx==1.18.0 onnxruntime==1.22.0 onnxscript==0.2.4 netron==8.4.3\n",
    "!pip install torch==2.6.0 torchvision==0.21.0 torchaudio==2.6.0 \\\n",
    "    --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c776e54a-b1dd-45c9-85e9-02bbff781061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required modules\n",
    "\n",
    "import onnx\n",
    "from onnx import helper\n",
    "from onnx import TensorProto\n",
    "import numpy as np\n",
    "import IPython\n",
    "import netron\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6b033bf-39f3-4a1c-aaed-e9a093dd1a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model specification\n",
    "input_size = 4\n",
    "hidden_size = 10\n",
    "output_size = 2\n",
    "\n",
    "onnx_opset = 18\n",
    "ir_version = 10\n",
    "onnx_model_path = \"mlp_model.onnx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1301da92-2433-47aa-9528-88485150adcd",
   "metadata": {},
   "source": [
    "##### Define input and output tensors of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d000755d-a6bf-4176-8006-550f07887e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input tensor (with dynamic batch size)\n",
    "X = helper.make_tensor_value_info(\n",
    "    name=\"input\",\n",
    "    elem_type=TensorProto.FLOAT,\n",
    "    shape=[\"batch\", input_size]  # [batch_size, input_size]\n",
    ")\n",
    "\n",
    "# Define output tensor\n",
    "Y = helper.make_tensor_value_info(\n",
    "    name=\"output\",\n",
    "    elem_type=TensorProto.FLOAT,\n",
    "    shape=[\"batch\", output_size]  # [batch_size, output_size]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca3d634-8d07-4d55-8424-5e25ab2458af",
   "metadata": {},
   "source": [
    "##### Create weights and biases as initializer of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25418328-d324-4d84-b67c-5d14f77cd63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights and biases for the first layer (input -> hidden)\n",
    "W1 = helper.make_tensor(\n",
    "    name=\"W1\",\n",
    "    data_type=TensorProto.FLOAT,\n",
    "    dims=[input_size, hidden_size],\n",
    "    vals=np.random.randn(input_size, hidden_size).astype(np.float32).flatten().tolist()\n",
    ")\n",
    "\n",
    "B1 = helper.make_tensor(\n",
    "    name=\"B1\",\n",
    "    data_type=TensorProto.FLOAT,\n",
    "    dims=[hidden_size],\n",
    "    vals=np.random.randn(hidden_size).astype(np.float32).flatten().tolist()\n",
    ")\n",
    "\n",
    "# Weights and biases for the second layer (hidden -> output)\n",
    "W2 = helper.make_tensor(\n",
    "    name=\"W2\",\n",
    "    data_type=TensorProto.FLOAT,\n",
    "    dims=[hidden_size, output_size],\n",
    "    vals=np.random.randn(hidden_size, output_size).astype(np.float32).flatten().tolist()\n",
    ")\n",
    "\n",
    "B2 = helper.make_tensor(\n",
    "    name=\"B2\",\n",
    "    data_type=TensorProto.FLOAT,\n",
    "    dims=[output_size],\n",
    "    vals=np.random.randn(output_size).astype(np.float32).flatten().tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30ddd50-7a1e-40b3-92d4-024919474fc0",
   "metadata": {},
   "source": [
    "##### Create nodes of the model\n",
    "##### Input -> Matmul -> Add -> Relu -> Matmul -> Add -> Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc894e8f-bc12-44a8-bd92-3d02d548a134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Node 1: X * W1 + B1\n",
    "node_matmul1 = helper.make_node(\n",
    "    op_type=\"MatMul\", inputs=[\"input\", \"W1\"], outputs=[\"matmul1_out\"], name=\"matmul1\"\n",
    ")\n",
    "\n",
    "node_add1 = helper.make_node(\n",
    "    op_type=\"Add\", inputs=[\"matmul1_out\", \"B1\"], outputs=[\"add1_out\"], name=\"add1\"\n",
    ")\n",
    "\n",
    "# Node 2: ReLU activation\n",
    "node_relu = helper.make_node(\n",
    "    op_type=\"Relu\", inputs=[\"add1_out\"], outputs=[\"relu_out\"], name=\"relu\"\n",
    ")\n",
    "\n",
    "# Node 3: relu_out * W2 + B2\n",
    "node_matmul2 = helper.make_node(\n",
    "    op_type=\"MatMul\", inputs=[\"relu_out\", \"W2\"], outputs=[\"matmul2_out\"], name=\"matmul2\"\n",
    ")\n",
    "\n",
    "node_add2 = helper.make_node(\n",
    "    op_type=\"Add\", inputs=[\"matmul2_out\", \"B2\"], outputs=[\"output\"], name=\"add2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6211b3-c877-4624-b26c-54dc846859f8",
   "metadata": {},
   "source": [
    "##### Assemble the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0f54eb0-851d-419b-97b9-8fa22b713099",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = helper.make_graph(\n",
    "    nodes=[node_matmul1, node_add1, node_relu, node_matmul2, node_add2],\n",
    "    name=\"2_layer_mlp\",\n",
    "    inputs=[X],\n",
    "    outputs=[Y],\n",
    "    initializer=[W1, B1, W2, B2]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9236a05a-3316-431d-b70b-b25081a1b2aa",
   "metadata": {},
   "source": [
    "##### Create model out of the graph and save ONNX model on the disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f0500cc-aeac-4960-9dd9-68f4aa6b89de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = helper.make_model(\n",
    "    graph,\n",
    "    producer_name=\"onnx-mlp-example\",\n",
    "    opset_imports=[helper.make_opsetid(\"\", onnx_opset)],\n",
    "    ir_version=ir_version, # ONNX opset version\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "onnx.save(model, onnx_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df054e8-1fc6-4eab-88ab-6ccab2d8d46f",
   "metadata": {},
   "source": [
    "##### Visualize the ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b72fde0-83d0-4ab1-b4fb-9ca4d9d7804c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serving 'mlp_model.onnx' at http://localhost:6006\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"http://localhost:6006\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fab37997a30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port = 6006\n",
    "netron.start(onnx_model_path, port, browse=False)\n",
    "IPython.display.IFrame(f\"http://localhost:{port}\", width=1000, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da57145d-9bb1-4aa4-9d9f-55e46d9a6e14",
   "metadata": {},
   "source": [
    "##### Model execution using ONNX Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6471b674-eb6f-41af-a3ab-274526ebd564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to run model\n",
    "\n",
    "def generate_random_input(model_path):\n",
    "    # Load model and inspect input shape\n",
    "    sess = ort.InferenceSession(model_path)\n",
    "    input_name = sess.get_inputs()[0].name\n",
    "    input_shape = sess.get_inputs()[0].shape\n",
    "    \n",
    "    # Replace dynamic dimensions (None) with 1\n",
    "    concrete_shape = [1 if isinstance(dim, str) else dim for dim in input_shape]\n",
    "    \n",
    "    # Generate random data\n",
    "    return {input_name: np.random.rand(*concrete_shape).astype(np.float32)}\n",
    "\n",
    "\n",
    "def run_model(model_path):\n",
    "    # Create inference session\n",
    "    sess = ort.InferenceSession(model_path)\n",
    "    \n",
    "    # Generate inputs\n",
    "    inputs = generate_random_input(model_path)\n",
    "    input_name = list(inputs.keys())[0]\n",
    "    \n",
    "    # Run model\n",
    "    outputs = sess.run(None, inputs)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nInput shape: {inputs[input_name].shape}\")\n",
    "    print(f\"Output shape: {outputs[0].shape}\")\n",
    "    print(\"\\nSample input values:\")\n",
    "    print(inputs[input_name][0, :5])  # First 5 elements of first sample\n",
    "    print(\"\\nSample output values:\")\n",
    "    print(outputs[0][0, :5])\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee7aa391-a2b6-4396-9675-d4b6f12a152e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input shape: (1, 4)\n",
      "Output shape: (1, 2)\n",
      "\n",
      "Sample input values:\n",
      "[0.6841185  0.77549195 0.66654027 0.2499431 ]\n",
      "\n",
      "Sample output values:\n",
      "[1.6343086 1.7021872]\n"
     ]
    }
   ],
   "source": [
    "# Run the model with generated inputs\n",
    "outputs = run_model(onnx_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b672cd74-68eb-4595-9394-c0e55f22327d",
   "metadata": {},
   "source": [
    "### Step-2 Developing ONNX model from scratch using ONNX Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128a44c1-b57a-47fd-beb9-a00b9ee96cf5",
   "metadata": {},
   "source": [
    "##### We will try to build the same model via ONNX Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c466c098-8fb7-40a7-b4f9-0f0d7f7fd867",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n"
     ]
    }
   ],
   "source": [
    "import onnxscript\n",
    "from onnxscript import opset18 as op\n",
    "from onnxscript import FLOAT\n",
    "import numpy as np\n",
    "\n",
    "onnx_model_path_onnxscript = \"mlp_model_onnxscript.onnx\"\n",
    "\n",
    "# Define model\n",
    "@onnxscript.script()\n",
    "def two_layer_nn(input: FLOAT[\"batch\", 4]) -> FLOAT[\"batch\", 2]:\n",
    "    # Layer 1: Linear (X * W1 + B1)\n",
    "\n",
    "    # Define weights and biases as constants\n",
    "    W1 = op.Constant(value=np.random.randn(4, 10).astype(np.float32))\n",
    "    B1 = op.Constant(value=np.random.randn(10).astype(np.float32))\n",
    "    # Define Matmul layer followed by Add\n",
    "    hidden = op.Add(op.MatMul(input, W1), B1)\n",
    "    \n",
    "    # ReLU activation\n",
    "    hidden = op.Relu(hidden)\n",
    "    \n",
    "    # Layer 2: Linear (hidden * W2 + B2)\n",
    "    # Define weights and biases as constants\n",
    "    W2 = op.Constant(value=np.random.randn(10, 2).astype(np.float32))\n",
    "    B2 = op.Constant(value=np.random.randn(2).astype(np.float32))\n",
    "    # Define Matmul layer followed by Add\n",
    "    output = op.Add(op.MatMul(hidden, W2), B2)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Convert to ONNX model\n",
    "model = two_layer_nn.to_model_proto()\n",
    "\n",
    "# Save to ONNX model\n",
    "onnx.save(model, onnx_model_path_onnxscript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "434999fd-2c0b-4aaa-baec-bad7c4331e38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serving 'mlp_model_onnxscript.onnx' at http://localhost:6007\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"http://localhost:6007\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fab379c08b0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port = 6007\n",
    "netron.start(onnx_model_path_onnxscript, port, browse=False)\n",
    "IPython.display.IFrame(f\"http://localhost:{port}\", width=1000, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab25fdf-baea-4741-b614-b5d0f90634c7",
   "metadata": {},
   "source": [
    "##### Model execution by calling ONNX Script model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7c4a780-d6f1-46ff-8d17-b9e75b22917e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample input values:\n",
      "[[-0.8897543 -1.3789165  1.4738988  1.2751241]]\n",
      "Sample output values:\n",
      "[[ 1.8809249 -1.6911085]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env_08_07/lib/python3.10/site-packages/onnxscript/evaluator.py:277: FutureWarning: 'onnxscript.values.OnnxFunction.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = function.param_schemas()\n"
     ]
    }
   ],
   "source": [
    "dummy_input = np.random.randn(1, 4).astype(np.float32)\n",
    "dummy_output = two_layer_nn(dummy_input)\n",
    "\n",
    "print(\"Sample input values:\")\n",
    "print(dummy_input)\n",
    "\n",
    "print(\"Sample output values:\")\n",
    "print(dummy_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede86623-3231-486a-9ecc-1863793fcd21",
   "metadata": {},
   "source": [
    "### Step-3 Custom Operator in ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bada6a1-4825-470c-84b5-085841c40c40",
   "metadata": {},
   "source": [
    "#### 3.1 Using ONNX Building Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "406bc342-d96a-47c0-91de-927baf13302b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ONNX model with SwiGLU!\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "from onnx import helper, TensorProto, numpy_helper\n",
    "\n",
    "\n",
    "# Build SwiGLU ONNX Function Proto\n",
    "def get_swiglu_function_proto(op_name, input_names, output_names, domain, opset):\n",
    "    # Define SwiGLU as a FunctionProto\n",
    "    x_inp, W_inp, V_inp = input_names\n",
    "    output = output_names[0]\n",
    "\n",
    "    swiglu_fn = helper.make_function(\n",
    "        domain=domain,  # Custom domain to avoid conflicts\n",
    "        fname=op_name,\n",
    "        inputs=input_names,\n",
    "        outputs=output_names,\n",
    "        nodes=[\n",
    "            # xW = MatMul(x, W)\n",
    "            helper.make_node(\"MatMul\", [x_inp, W_inp], [\"xW\"], name=\"matmul_xW\"),\n",
    "            # sigmoid_xW = Sigmoid(xW)\n",
    "            helper.make_node(\"Sigmoid\", [\"xW\"], [\"sigmoid_xW\"], name=\"sigmoid\"),\n",
    "            # swish_xW = Mul(xW, sigmoid_xW)\n",
    "            helper.make_node(\"Mul\", [\"xW\", \"sigmoid_xW\"], [\"swish_xW\"], name=\"swish\"),\n",
    "            # xV = MatMul(x, V)\n",
    "            helper.make_node(\"MatMul\", [x_inp, V_inp], [\"xV\"], name=\"matmul_xV\"),\n",
    "            # output = Mul(swish_xW, xV)\n",
    "            helper.make_node(\"Mul\", [\"swish_xW\", \"xV\"], [output], name=\"mul_swish\"),\n",
    "        ],\n",
    "        opset_imports=[helper.make_opsetid(\"\", opset)],  # ONNX opset version\n",
    "    )\n",
    "    return swiglu_fn\n",
    "\n",
    "\n",
    "# Build the Model Graph\n",
    "def construct_graph():\n",
    "    # Define Model Weights (Initializers)\n",
    "    # Layer 1: 4x10 weight + 10 bias\n",
    "    W1 = numpy_helper.from_array(np.random.randn(4, 10).astype(np.float32), name=\"W1\")\n",
    "    B1 = numpy_helper.from_array(np.random.randn(10).astype(np.float32), name=\"B1\")\n",
    "\n",
    "    # SwiGLU: Two 10x10 weights (W and V)\n",
    "    W_swiglu = numpy_helper.from_array(\n",
    "        np.random.randn(10, 10).astype(np.float32), name=\"W_swiglu\"\n",
    "    )\n",
    "    V_swiglu = numpy_helper.from_array(\n",
    "        np.random.randn(10, 10).astype(np.float32), name=\"V_swiglu\"\n",
    "    )\n",
    "\n",
    "    # Layer 2: 10x2 weight + 2 bias\n",
    "    W2 = numpy_helper.from_array(np.random.randn(10, 2).astype(np.float32), name=\"W2\")\n",
    "    B2 = numpy_helper.from_array(np.random.randn(2).astype(np.float32), name=\"B2\")\n",
    "\n",
    "    graph = helper.make_graph(\n",
    "        name=\"SwiGLU_Linear_Model\",\n",
    "        inputs=[\n",
    "            helper.make_tensor_value_info(\"input\", TensorProto.FLOAT, [\"batch\", 4]),\n",
    "        ],\n",
    "        outputs=[\n",
    "            helper.make_tensor_value_info(\"output\", TensorProto.FLOAT, [\"batch\", 2]),\n",
    "        ],\n",
    "        nodes=[\n",
    "            # Layer 1: MatMul -> Add\n",
    "            helper.make_node(\n",
    "                \"MatMul\", [\"input\", \"W1\"], [\"matmul1_out\"], name=\"matmul1\"\n",
    "            ),\n",
    "            helper.make_node(\"Add\", [\"matmul1_out\", \"B1\"], [\"add1_out\"], name=\"add1\"),\n",
    "            # SwiGLU\n",
    "            helper.make_node(\n",
    "                \"SwiGLU\",\n",
    "                inputs=[\"add1_out\", \"W_swiglu\", \"V_swiglu\"],\n",
    "                outputs=[\"swiglu_out\"],\n",
    "                domain=custom_op_domain,\n",
    "                name=\"swiglu\",\n",
    "            ),\n",
    "            # Layer 2: MatMul -> Add\n",
    "            helper.make_node(\n",
    "                \"MatMul\", [\"swiglu_out\", \"W2\"], [\"matmul2_out\"], name=\"matmul2\"\n",
    "            ),\n",
    "            helper.make_node(\"Add\", [\"matmul2_out\", \"B2\"], [\"output\"], name=\"add2\"),\n",
    "        ],\n",
    "        initializer=[W1, B1, W_swiglu, V_swiglu, W2, B2],\n",
    "    )\n",
    "    return graph\n",
    "\n",
    "\n",
    "# Create and Save the Model\n",
    "def construct_model_proto(custom_op_domain, custom_op_opset, model_opset, ir_version):\n",
    "    swiglu_fn = get_swiglu_function_proto(\n",
    "        \"SwiGLU\", [\"x\", \"W\", \"V\"], [\"output\"], custom_op_domain, model_opset\n",
    "    )\n",
    "\n",
    "    graph = construct_graph()\n",
    "\n",
    "    model = helper.make_model(\n",
    "        graph,\n",
    "        functions=[swiglu_fn],\n",
    "        opset_imports=[\n",
    "            helper.make_opsetid(\"\", model_opset),  # ONNX opset\n",
    "            helper.make_opsetid(custom_op_domain, custom_op_opset),  # Custom domain\n",
    "        ],\n",
    "        ir_version=ir_version,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "custom_op_domain = \"my.custom_op\"\n",
    "custom_op_opset = 1\n",
    "model_opset = 18\n",
    "ir_version = 10\n",
    "model = construct_model_proto(custom_op_domain, custom_op_opset, model_opset, ir_version)\n",
    "\n",
    "swiglu_model_onnx_apis = \"swiglu_model_onnx_apis.onnx\"\n",
    "onnx.save(model, swiglu_model_onnx_apis)\n",
    "print(\"Saved ONNX model with SwiGLU!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18b5457e-7af5-449a-9251-482f40bcb5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serving 'swiglu_model_onnx_apis.onnx' at http://localhost:6008\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"http://localhost:6008\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fab37994f70>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port = 6008\n",
    "netron.start(swiglu_model_onnx_apis, port, browse=False)\n",
    "IPython.display.IFrame(f\"http://localhost:{port}\", width=1000, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a4f6e61-5af7-408e-ba4b-aed981e6193b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input shape: (1, 4)\n",
      "Output shape: (1, 2)\n",
      "\n",
      "Sample input values:\n",
      "[0.21669818 0.2543661  0.14980361 0.985594  ]\n",
      "\n",
      "Sample output values:\n",
      "[26.734856 37.842915]\n"
     ]
    }
   ],
   "source": [
    "# Run the model with generated inputs\n",
    "outputs = run_model(swiglu_model_onnx_apis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df56e102-5c27-4291-9621-4d07014e1212",
   "metadata": {},
   "source": [
    "#### 3.2 Using ONNX Script tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03f6aaf2-9e06-4dfc-9262-ce63d9c69eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved ONNX model with SwiGLU using ONNX Script!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import onnxscript\n",
    "from onnxscript import opset18 as op\n",
    "from onnxscript import FLOAT, script\n",
    "\n",
    "custom_op_domain = \"my.custom_op\"\n",
    "custom_op_opset = 1\n",
    "model_opset = 18\n",
    "ir_version = 10\n",
    "custom_opset = onnxscript.values.Opset(custom_op_domain, custom_op_opset)\n",
    "\n",
    "# Define the custom SwiGLU function using ONNX Script\n",
    "@onnxscript.script(opset=custom_opset)\n",
    "def SwiGLU(x: FLOAT[...], W: FLOAT[...], V: FLOAT[...]) -> FLOAT[...]:\n",
    "    xW = op.MatMul(x, W)\n",
    "    sigmoid_xW = op.Sigmoid(xW)\n",
    "    swish_xW = op.Mul(xW, sigmoid_xW)\n",
    "    xV = op.MatMul(x, V)\n",
    "    output = op.Mul(swish_xW, xV)\n",
    "    return output\n",
    "\n",
    "# Define the main model\n",
    "@onnxscript.script()\n",
    "def SwiGLU_Model(input: FLOAT[\"batch\", 4]) -> FLOAT[\"batch\", 2]:\n",
    "    # Layer 1 weights\n",
    "    W1 = op.Constant(value=np.random.randn(4, 10).astype(np.float32))\n",
    "    B1 = op.Constant(value=np.random.randn(10).astype(np.float32))\n",
    "    \n",
    "    # SwiGLU weights\n",
    "    W_swiglu = op.Constant(value=np.random.randn(10, 10).astype(np.float32))\n",
    "    V_swiglu = op.Constant(value=np.random.randn(10, 10).astype(np.float32))\n",
    "    \n",
    "    # Layer 2 weights\n",
    "    W2 = op.Constant(value=np.random.randn(10, 2).astype(np.float32))\n",
    "    B2 = op.Constant(value=np.random.randn(2).astype(np.float32))\n",
    "    \n",
    "    # Layer 1: MatMul -> Add\n",
    "    matmul1_out = op.MatMul(input, W1)\n",
    "    add1_out = op.Add(matmul1_out, B1)\n",
    "    \n",
    "    # SwiGLU\n",
    "    swiglu_out = SwiGLU(add1_out, W_swiglu, V_swiglu)\n",
    "    \n",
    "    # Layer 2: MatMul -> Add\n",
    "    matmul2_out = op.MatMul(swiglu_out, W2)\n",
    "    output = op.Add(matmul2_out, B2)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Convert to ONNX model\n",
    "model = SwiGLU_Model.to_model_proto()\n",
    "\n",
    "# Save the model\n",
    "swiglu_model_onnx_script = \"swiglu_model_onnx_script.onnx\"\n",
    "onnx.save(model, swiglu_model_onnx_script)\n",
    "print(\"Saved ONNX model with SwiGLU using ONNX Script!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c495704-2138-4d90-8a95-55f38261be74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serving 'swiglu_model_onnx_script.onnx' at http://localhost:6009\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"http://localhost:6009\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fab37996e00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port = 6009\n",
    "netron.start(swiglu_model_onnx_script, port, browse=False)\n",
    "IPython.display.IFrame(f\"http://localhost:{port}\", width=1000, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fc19f18-d4e5-44c4-9980-1fdecdd08709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input shape: (1, 4)\n",
      "Output shape: (1, 2)\n",
      "\n",
      "Sample input values:\n",
      "[0.6029944  0.81271684 0.7339709  0.5977562 ]\n",
      "\n",
      "Sample output values:\n",
      "[ -1.5772581 -17.073538 ]\n"
     ]
    }
   ],
   "source": [
    "# Run the model with generated inputs\n",
    "outputs = run_model(swiglu_model_onnx_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665d5bdd-c563-4716-a4d3-e19e2136f4d5",
   "metadata": {},
   "source": [
    "#### 3.3 Using Pytorch export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78da33ec-ba05-4559-8f3a-2832026793cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully exported PyTorch model with custom SwiGLU op!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import onnxscript\n",
    "\n",
    "custom_op_domain = \"my_custom_op\"\n",
    "custom_op_opset = 1\n",
    "model_opset = 18\n",
    "swiglu_model_pytorch_export = \"swiglu_pytorch_exported.onnx\"\n",
    "custom_opset = onnxscript.values.Opset(custom_op_domain, custom_op_opset)\n",
    "\n",
    "\n",
    "# Define the custom SwiGLU function using ONNX Script\n",
    "@script(opset=custom_opset)\n",
    "def SwiGLU(x: FLOAT[...], W: FLOAT[...], V: FLOAT[...]) -> FLOAT[...]:\n",
    "    xW = op.MatMul(x, W)\n",
    "    sigmoid_xW = op.Sigmoid(xW)\n",
    "    swish_xW = op.Mul(xW, sigmoid_xW)\n",
    "    xV = op.MatMul(x, V)\n",
    "    output = op.Mul(swish_xW, xV)\n",
    "    return output\n",
    "\n",
    "\n",
    "# 1. Define the SwiGLU custom PyTorch operation\n",
    "class SwiGLUFunction(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, W, V):\n",
    "        ctx.save_for_backward(x, W, V)\n",
    "        xW = torch.matmul(x, W)\n",
    "        sigmoid = torch.sigmoid(xW)\n",
    "        swish = xW * sigmoid\n",
    "        xV = torch.matmul(x, V)\n",
    "        return swish * xV\n",
    "\n",
    "    @staticmethod\n",
    "    def symbolic(g, x, W, V):\n",
    "        return g.onnxscript_op(SwiGLU, x, W, V).setType(\n",
    "            x.type().with_sizes([None, V.type().sizes()[1]])\n",
    "        )\n",
    "\n",
    "\n",
    "# 2. Create PyTorch model\n",
    "class SwiGLUModel(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_dim, hidden_dim, bias=True)\n",
    "        self.W_swiglu = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
    "        self.V_swiglu = nn.Parameter(torch.randn(hidden_dim, hidden_dim))\n",
    "        self.linear2 = nn.Linear(hidden_dim, out_dim, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = SwiGLUFunction.apply(x, self.W_swiglu, self.V_swiglu)\n",
    "        return self.linear2(x)\n",
    "\n",
    "\n",
    "# 3. Register the custom symbolic function\n",
    "torch.onnx.register_custom_op_symbolic(\n",
    "    f\"{custom_op_domain}::SwiGLU\",\n",
    "    SwiGLUFunction.symbolic,\n",
    "    opset_version=model_opset,\n",
    ")\n",
    "\n",
    "# 4. Create and export the model\n",
    "model = SwiGLUModel(4, 2, 10)\n",
    "dummy_input = torch.randn(1, 4)  # Single example\n",
    "\n",
    "# Export to ONNX\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,  # Pass the tensor directly\n",
    "    swiglu_model_pytorch_export,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\"input\": {0: \"batch\"}, \"output\": {0: \"batch\"}},\n",
    "    opset_version=model_opset,\n",
    "    custom_opsets={custom_op_domain: custom_op_opset},  # Must match registration domain\n",
    ")\n",
    "\n",
    "print(\"Successfully exported PyTorch model with custom SwiGLU op!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "972d2f04-6e9e-4d82-bfc0-472845f33ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Serving 'swiglu_pytorch_exported.onnx' at http://localhost:6010\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"500\"\n",
       "            src=\"http://localhost:6010\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fab15836920>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port = 6010\n",
    "netron.start(swiglu_model_pytorch_export, port, browse=False)\n",
    "IPython.display.IFrame(f\"http://localhost:{port}\", width=1000, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "119f45f3-6faa-4704-82ef-2d686e2cfbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input shape: (1, 4)\n",
      "Output shape: (1, 2)\n",
      "\n",
      "Sample input values:\n",
      "[0.66730917 0.4363972  0.39824814 0.6516445 ]\n",
      "\n",
      "Sample output values:\n",
      "[-0.68956697  0.33889443]\n"
     ]
    }
   ],
   "source": [
    "# Run the model with generated inputs\n",
    "outputs = run_model(swiglu_model_pytorch_export)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
