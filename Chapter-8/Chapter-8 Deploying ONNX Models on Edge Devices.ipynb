{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b122880-d1f0-4252-90fa-52c6d8613ea4",
   "metadata": {},
   "source": [
    "# Chapter-8 Deploying ONNX Models on Edge Devices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf6f5d-a611-402c-a39c-34601be3061c",
   "metadata": {},
   "source": [
    "#### In this notebook, we will learn about ONNX Runtime C++ APIs and see how ONNX Runtime can be used to deploy the models on the edge devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aecbada-3582-43f2-9d31-313ad87e557f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-04-05 16:04:16--  https://github.com/microsoft/onnxruntime/releases/download/v1.21.0/onnxruntime-linux-x64-1.21.0.tgz\n",
      "Resolving github.com (github.com)... 20.207.73.82\n",
      "connected. to github.com (github.com)|20.207.73.82|:443... \n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/156939672/d9f524e2-f059-49ca-a237-afa886d0f73e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250405%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250405T103416Z&X-Amz-Expires=300&X-Amz-Signature=c9502af3d1554b3891cea20aff3418928241dda073f1ece887cac62af99103d8&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Donnxruntime-linux-x64-1.21.0.tgz&response-content-type=application%2Foctet-stream [following]\n",
      "--2025-04-05 16:04:17--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/156939672/d9f524e2-f059-49ca-a237-afa886d0f73e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250405%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250405T103416Z&X-Amz-Expires=300&X-Amz-Signature=c9502af3d1554b3891cea20aff3418928241dda073f1ece887cac62af99103d8&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Donnxruntime-linux-x64-1.21.0.tgz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "connected. to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... \n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 7585530 (7.2M) [application/octet-stream]\n",
      "Saving to: ‘onnxruntime-linux-x64-1.21.0.tgz’\n",
      "\n",
      "onnxruntime-linux-x 100%[===================>]   7.23M  17.1MB/s    in 0.4s    \n",
      "\n",
      "2025-04-05 16:04:18 (17.1 MB/s) - ‘onnxruntime-linux-x64-1.21.0.tgz’ saved [7585530/7585530]\n",
      "\n",
      "onnxruntime-linux-x64-1.21.0/\n",
      "onnxruntime-linux-x64-1.21.0/include/\n",
      "onnxruntime-linux-x64-1.21.0/include/core/\n",
      "onnxruntime-linux-x64-1.21.0/include/core/providers/\n",
      "onnxruntime-linux-x64-1.21.0/include/core/providers/resource.h\n",
      "onnxruntime-linux-x64-1.21.0/include/core/providers/custom_op_context.h\n",
      "onnxruntime-linux-x64-1.21.0/include/onnxruntime_run_options_config_keys.h\n",
      "onnxruntime-linux-x64-1.21.0/include/cpu_provider_factory.h\n",
      "onnxruntime-linux-x64-1.21.0/include/onnxruntime_lite_custom_op.h\n",
      "onnxruntime-linux-x64-1.21.0/include/onnxruntime_cxx_api.h\n",
      "onnxruntime-linux-x64-1.21.0/include/onnxruntime_cxx_inline.h\n",
      "onnxruntime-linux-x64-1.21.0/include/onnxruntime_float16.h\n",
      "onnxruntime-linux-x64-1.21.0/include/onnxruntime_c_api.h\n",
      "onnxruntime-linux-x64-1.21.0/include/onnxruntime_session_options_config_keys.h\n",
      "onnxruntime-linux-x64-1.21.0/include/provider_options.h\n",
      "onnxruntime-linux-x64-1.21.0/LICENSE\n",
      "onnxruntime-linux-x64-1.21.0/ThirdPartyNotices.txt\n",
      "onnxruntime-linux-x64-1.21.0/lib/\n",
      "onnxruntime-linux-x64-1.21.0/lib/cmake/\n",
      "onnxruntime-linux-x64-1.21.0/lib/cmake/onnxruntime/\n",
      "onnxruntime-linux-x64-1.21.0/lib/cmake/onnxruntime/onnxruntimeTargets-release.cmake\n",
      "onnxruntime-linux-x64-1.21.0/lib/cmake/onnxruntime/onnxruntimeConfigVersion.cmake\n",
      "onnxruntime-linux-x64-1.21.0/lib/cmake/onnxruntime/onnxruntimeTargets.cmake\n",
      "onnxruntime-linux-x64-1.21.0/lib/cmake/onnxruntime/onnxruntimeConfig.cmake\n",
      "onnxruntime-linux-x64-1.21.0/lib/libonnxruntime.so.1\n",
      "onnxruntime-linux-x64-1.21.0/lib/libonnxruntime.so\n",
      "onnxruntime-linux-x64-1.21.0/lib/pkgconfig/\n",
      "onnxruntime-linux-x64-1.21.0/lib/pkgconfig/libonnxruntime.pc\n",
      "onnxruntime-linux-x64-1.21.0/lib/libonnxruntime_providers_shared.so\n",
      "onnxruntime-linux-x64-1.21.0/lib/libonnxruntime.so.1.21.0\n",
      "onnxruntime-linux-x64-1.21.0/VERSION_NUMBER\n",
      "onnxruntime-linux-x64-1.21.0/Privacy.md\n",
      "onnxruntime-linux-x64-1.21.0/GIT_COMMIT_ID\n",
      "onnxruntime-linux-x64-1.21.0/README.md\n",
      "/mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/Ultimate-ONNX-for-Optimizing-Deep-Learning-Models/Chapter-7/deps\n",
      "--2025-04-05 16:04:19--  https://raw.githubusercontent.com/nothings/stb/master/stb_image.h\n",
      "185.199.108.133, 185.199.109.133, 185.199.110.133, ...tent.com)... \n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/onnx_env/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 OK\n",
      "Length: 283010 (276K) [text/plain]\n",
      "Saving to: ‘stb_image.h’\n",
      "\n",
      "stb_image.h         100%[===================>] 276.38K  --.-KB/s    in 0.04s   \n",
      "\n",
      "2025-04-05 16:04:19 (6.18 MB/s) - ‘stb_image.h’ saved [283010/283010]\n",
      "\n",
      "--2025-04-05 16:04:19--  https://raw.githubusercontent.com/nothings/stb/master/stb_image_resize2.h\n",
      "185.199.111.133, 185.199.110.133, 185.199.109.133, ...tent.com)... \n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 452529 (442K) [text/plain]\n",
      "Saving to: ‘stb_image_resize2.h’\n",
      "\n",
      "stb_image_resize2.h 100%[===================>] 441.92K  --.-KB/s    in 0.05s   \n",
      "\n",
      "2025-04-05 16:04:20 (8.55 MB/s) - ‘stb_image_resize2.h’ saved [452529/452529]\n",
      "\n",
      "/mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/Ultimate-ONNX-for-Optimizing-Deep-Learning-Models/Chapter-7/data\n",
      "--2025-04-05 16:04:20--  https://github.com/onnx/models/raw/refs/heads/main/validated/vision/classification/resnet/model/resnet50-v2-7.onnx\n",
      "20.207.73.82thub.com (github.com)... \n",
      "Connecting to github.com (github.com)|20.207.73.82|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://media.githubusercontent.com/media/onnx/models/refs/heads/main/validated/vision/classification/resnet/model/resnet50-v2-7.onnx [following]\n",
      "--2025-04-05 16:04:20--  https://media.githubusercontent.com/media/onnx/models/refs/heads/main/validated/vision/classification/resnet/model/resnet50-v2-7.onnx\n",
      "185.199.108.133, 185.199.109.133, 185.199.110.133, ...rcontent.com)... \n",
      "Connecting to media.githubusercontent.com (media.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 102442452 (98M) [application/octet-stream]\n",
      "Saving to: ‘resnet50-v2-7.onnx’\n",
      "\n",
      "resnet50-v2-7.onnx  100%[===================>]  97.70M  12.3MB/s    in 8.9s    \n",
      "\n",
      "2025-04-05 16:04:29 (11.0 MB/s) - ‘resnet50-v2-7.onnx’ saved [102442452/102442452]\n",
      "\n",
      "--2025-04-05 16:04:30--  https://huggingface.co/spaces/ClassCat/ViT-ImageNet-Classification/resolve/main/samples/cat.jpg\n",
      "99.86.182.94, 99.86.182.39, 99.86.182.72, ...\n",
      "Connecting to huggingface.co (huggingface.co)|99.86.182.94|:443... connected.\n",
      "200 OKequest sent, awaiting response... \n",
      "Length: 5792 (5.7K) [image/jpeg]\n",
      "Saving to: ‘cat.jpg’\n",
      "\n",
      "cat.jpg             100%[===================>]   5.66K  --.-KB/s    in 0s      \n",
      "\n",
      "2025-04-05 16:04:30 (1.09 GB/s) - ‘cat.jpg’ saved [5792/5792]\n",
      "\n",
      "/mnt/d/Meet/Company/Orange Eva Publication/Jupyter Notebook/Ultimate-ONNX-for-Optimizing-Deep-Learning-Models/Chapter-7\n"
     ]
    }
   ],
   "source": [
    "# Download ONNX Runtime Prebuilt binaries\n",
    "\n",
    "# Below binaries are for linux x64 system \n",
    "!wget https://github.com/microsoft/onnxruntime/releases/download/v1.21.0/onnxruntime-linux-x64-1.21.0.tgz\n",
    "!tar -xzvf onnxruntime-linux-x64-1.21.0.tgz\n",
    "\n",
    "# Uncomment below line to download binaries for Raspberry Pi 3B+ (Bookworm)\n",
    "# !wget https://github.com/ava-orange-education/Ultimate-ONNX-for-Optimizing-Deep-Learning-Models/releases/download/v1.22.0/onnxruntime-linux-aarch64-1.22.0.zip\n",
    "\n",
    "!mkdir deps/\n",
    "!mkdir data/\n",
    "\n",
    "%cd deps\n",
    "# Download image processing helper libraries\n",
    "!wget https://raw.githubusercontent.com/nothings/stb/master/stb_image.h -O stb_image.h\n",
    "!wget https://raw.githubusercontent.com/nothings/stb/master/stb_image_resize2.h -O stb_image_resize2.h\n",
    "\n",
    "%cd ../data\n",
    "# Download ResNet50 model from Onnx model zoo\n",
    "!wget https://github.com/onnx/models/raw/refs/heads/main/validated/vision/classification/resnet/model/resnet50-v2-7.onnx\n",
    "\n",
    "# Download a sample image of cat\n",
    "!wget https://huggingface.co/spaces/ClassCat/ViT-ImageNet-Classification/resolve/main/samples/cat.jpg\n",
    "\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19639e06-5b97-4cad-b101-aa305e371688",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpp_content = \"\"\"\n",
    "#include <iostream>\n",
    "#include <vector>\n",
    "#include <chrono>\n",
    "#include <onnxruntime_cxx_api.h>\n",
    "\n",
    "#define STB_IMAGE_IMPLEMENTATION\n",
    "#define STB_IMAGE_RESIZE2_IMPLEMENTATION\n",
    "#include <stb_image.h>\n",
    "#include <stb_image_resize2.h>\n",
    "\n",
    "\n",
    "// ImageNet mean and std values\n",
    "const float mean[] = {0.485f, 0.456f, 0.406f};\n",
    "const float std_dev[] = {0.229f, 0.224f, 0.225f};\n",
    "\n",
    "void preprocessImage(const std::string& imagePath, std::vector<float>& inputTensorValues) {\n",
    "    int width, height, channels;\n",
    "    unsigned char* img = stbi_load(imagePath.c_str(), &width, &height, &channels, 3); // Load as RGB\n",
    "\n",
    "    if (!img) {\n",
    "        throw std::runtime_error(\"Failed to load image: \" + imagePath);\n",
    "    }\n",
    "\n",
    "    int target_width = 224, target_height = 224;\n",
    "    std::vector<unsigned char> resized_img(target_width * target_height * 3);\n",
    "\n",
    "    // Resize image to 224x224\n",
    "    stbir_resize_uint8_linear(img, width, height, 0,\n",
    "                       resized_img.data(), target_width, target_height, 0, STBIR_RGB);\n",
    "\n",
    "    // Convert to normalized float format (CHW layout)\n",
    "    for (int c = 0; c < 3; c++) {  // Loop over channels\n",
    "        for (int h = 0; h < target_height; h++) {\n",
    "            for (int w = 0; w < target_width; w++) {\n",
    "                int idx = (h * target_width + w) * 3 + c;  // HWC index\n",
    "                inputTensorValues[c * target_width * target_height + h * target_width + w] =\n",
    "                    ((float)resized_img[idx] / 255.0f - mean[c]) / std_dev[c];  // Normalize & Standardize\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    stbi_image_free(img);\n",
    "}\n",
    "\n",
    "int main(int argc, char* argv[]) {\n",
    "    if (argc < 3) {\n",
    "        std::cerr << \"Usage: \" << argv[0] << \" <model_path.onnx> <image_path.jpg>\" << std::endl;\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    std::string model_path = argv[1];\n",
    "    std::string img_path = argv[2];\n",
    "    \n",
    "    int model_height = 224;\n",
    "    int model_width = 224;\n",
    "    int num_channels = 3;\n",
    "\n",
    "    try {\n",
    "        Ort::Env env(ORT_LOGGING_LEVEL_WARNING, \"ONNXRuntimeTest\");\n",
    "        Ort::SessionOptions session_options;\n",
    "\n",
    "        // Load model\n",
    "        Ort::Session session(env, model_path.c_str(), session_options);\n",
    "        Ort::AllocatorWithDefaultOptions allocator;\n",
    "\n",
    "        // Get input details\n",
    "        auto input_name = session.GetInputNameAllocated(0, allocator);\n",
    "        std::vector<int64_t> input_shape = {1, num_channels, model_height, model_width}; // Batch size 1\n",
    "        \n",
    "        // Preprocess image\n",
    "        std::vector<float> input_tensor_values(num_channels * model_height * model_width, 0.0f);\n",
    "        preprocessImage(img_path, input_tensor_values);\n",
    "        \n",
    "        // Create input tensor\n",
    "        Ort::MemoryInfo memory_info = Ort::MemoryInfo::CreateCpu(OrtArenaAllocator, OrtMemTypeDefault);\n",
    "        Ort::Value input_tensor = Ort::Value::CreateTensor<float>(memory_info, input_tensor_values.data(),\n",
    "                            input_tensor_values.size(), input_shape.data(), input_shape.size());\n",
    "        \n",
    "        // Run inference\n",
    "        std::vector<const char*> input_names = {input_name.get()};\n",
    "        auto output_name = session.GetOutputNameAllocated(0, allocator);\n",
    "        std::vector<const char*> output_names = {output_name.get()};\n",
    "        \n",
    "        int num_iter = 10;\n",
    "        std::vector<Ort::Value> output_tensors;\n",
    "        \n",
    "        std::cout << \"Execution started.\" << std::endl;\n",
    "        auto start = std::chrono::high_resolution_clock::now();\n",
    "        for (int i = 0; i < num_iter; ++i) {\n",
    "            output_tensors = session.Run(Ort::RunOptions{nullptr}, input_names.data(),\n",
    "                                                                    &input_tensor, 1, output_names.data(), 1);\n",
    "        }\n",
    "        auto end = std::chrono::high_resolution_clock::now();\n",
    "        std::chrono::duration<double> duration = end - start;\n",
    "        std::cout << \"ORT Inference Time: \" << duration.count() / num_iter << \" seconds\" << std::endl;\n",
    "\n",
    "\n",
    "        // Print top-1 predicted class index\n",
    "        float* output_data = output_tensors[0].GetTensorMutableData<float>();\n",
    "\n",
    "        int predicted_class = std::max_element(output_data, output_data + 1000) - output_data;\n",
    "        std::cout << \"Predicted Class: \" << predicted_class << std::endl;\n",
    "\n",
    "    } catch (const Ort::Exception& e) {\n",
    "        std::cerr << \"Error: \" << e.what() << std::endl;\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "with open(\"resnet_inference.cpp\", \"w\") as f:\n",
    "    f.writelines(cpp_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e1296c-1d9a-4791-bc5a-3276ec5d8b1d",
   "metadata": {},
   "source": [
    "The above C++ code will load image of cat as shown below. \n",
    "\n",
    "![Image of Cat](https://huggingface.co/spaces/ClassCat/ViT-ImageNet-Classification/resolve/main/samples/cat.jpg)\n",
    "\n",
    "After loading the image, it will be resized to 224x224 pixels and standardized according to ImageNet norms. Once the image is preprocessed, it will be passed to the ONNX Runtime session for prediction. The model is expected to classify it as class 282, which corresponds to \"tiger cat,\" the closest match to a cat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a6cd7b5-0abc-49e6-84ed-f63a02984faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the cpp file\n",
    "!g++ -std=c++17 -I./onnxruntime-linux-x64-1.21.0/include -I./deps/ -L./onnxruntime-linux-x64-1.21.0/lib -o resnet_inference resnet_inference.cpp -lonnxruntime "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5f3cfee-bf6b-4ef3-8c88-ae3a1bab4a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution started.\n",
      "ORT Inference Time: 0.0216264 seconds\n",
      "Predicted Class: 282\n"
     ]
    }
   ],
   "source": [
    "# Add ONNX Runtime library path in LD_LIBRARY_PATH as we have dynamically linked this library during compilation and Run the inference\n",
    "!LD_LIBRARY_PATH=./onnxruntime-linux-x64-1.21.0/lib:$LD_LIBRARY_PATH ./resnet_inference ./data/resnet50-v2-7.onnx ./data/cat.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92739e6e-05e3-4505-9091-ec51b782c801",
   "metadata": {},
   "source": [
    "##### Note: The inference time presented above, is obtained on Linux-x64 machine. The same exercise can be done on Raspberry Pi 3B+."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
